{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "showing info https://raw.githubusercontent.com/nltk/nltk_data/gh-pages/index.xml\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import brown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1161192"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(brown.words())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "57340"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(brown.sents())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['The',\n",
       " 'Fulton',\n",
       " 'County',\n",
       " 'Grand',\n",
       " 'Jury',\n",
       " 'said',\n",
       " 'Friday',\n",
       " 'an',\n",
       " 'investigation',\n",
       " 'of',\n",
       " \"Atlanta's\",\n",
       " 'recent',\n",
       " 'primary',\n",
       " 'election',\n",
       " 'produced',\n",
       " '``',\n",
       " 'no',\n",
       " 'evidence',\n",
       " \"''\",\n",
       " 'that',\n",
       " 'any',\n",
       " 'irregularities',\n",
       " 'took',\n",
       " 'place',\n",
       " '.']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "brown.sents()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('The', 'AT'),\n",
       " ('Fulton', 'NP-TL'),\n",
       " ('County', 'NN-TL'),\n",
       " ('Grand', 'JJ-TL'),\n",
       " ('Jury', 'NN-TL'),\n",
       " ('said', 'VBD'),\n",
       " ('Friday', 'NR'),\n",
       " ('an', 'AT'),\n",
       " ('investigation', 'NN'),\n",
       " ('of', 'IN')]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "brown.tagged_words()[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(: opening parenthesis\n",
      "    (\n",
      "): closing parenthesis\n",
      "    )\n",
      "*: negator\n",
      "    not n't\n",
      ",: comma\n",
      "    ,\n",
      "--: dash\n",
      "    --\n",
      ".: sentence terminator\n",
      "    . ? ; ! :\n",
      ":: colon\n",
      "    :\n",
      "ABL: determiner/pronoun, pre-qualifier\n",
      "    quite such rather\n",
      "ABN: determiner/pronoun, pre-quantifier\n",
      "    all half many nary\n",
      "ABX: determiner/pronoun, double conjunction or pre-quantifier\n",
      "    both\n",
      "AP: determiner/pronoun, post-determiner\n",
      "    many other next more last former little several enough most least only\n",
      "    very few fewer past same Last latter less single plenty 'nough lesser\n",
      "    certain various manye next-to-last particular final previous present\n",
      "    nuf\n",
      "AP$: determiner/pronoun, post-determiner, genitive\n",
      "    other's\n",
      "AP+AP: determiner/pronoun, post-determiner, hyphenated pair\n",
      "    many-much\n",
      "AT: article\n",
      "    the an no a every th' ever' ye\n",
      "BE: verb 'to be', infinitive or imperative\n",
      "    be\n",
      "BED: verb 'to be', past tense, 2nd person singular or all persons plural\n",
      "    were\n",
      "BED*: verb 'to be', past tense, 2nd person singular or all persons plural, negated\n",
      "    weren't\n",
      "BEDZ: verb 'to be', past tense, 1st and 3rd person singular\n",
      "    was\n",
      "BEDZ*: verb 'to be', past tense, 1st and 3rd person singular, negated\n",
      "    wasn't\n",
      "BEG: verb 'to be', present participle or gerund\n",
      "    being\n",
      "BEM: verb 'to be', present tense, 1st person singular\n",
      "    am\n",
      "BEM*: verb 'to be', present tense, 1st person singular, negated\n",
      "    ain't\n",
      "BEN: verb 'to be', past participle\n",
      "    been\n",
      "BER: verb 'to be', present tense, 2nd person singular or all persons plural\n",
      "    are art\n",
      "BER*: verb 'to be', present tense, 2nd person singular or all persons plural, negated\n",
      "    aren't ain't\n",
      "BEZ: verb 'to be', present tense, 3rd person singular\n",
      "    is\n",
      "BEZ*: verb 'to be', present tense, 3rd person singular, negated\n",
      "    isn't ain't\n",
      "CC: conjunction, coordinating\n",
      "    and or but plus & either neither nor yet 'n' and/or minus an'\n",
      "CD: numeral, cardinal\n",
      "    two one 1 four 2 1913 71 74 637 1937 8 five three million 87-31 29-5\n",
      "    seven 1,119 fifty-three 7.5 billion hundred 125,000 1,700 60 100 six\n",
      "    ...\n",
      "CD$: numeral, cardinal, genitive\n",
      "    1960's 1961's .404's\n",
      "CS: conjunction, subordinating\n",
      "    that as after whether before while like because if since for than altho\n",
      "    until so unless though providing once lest s'posin' till whereas\n",
      "    whereupon supposing tho' albeit then so's 'fore\n",
      "DO: verb 'to do', uninflected present tense, infinitive or imperative\n",
      "    do dost\n",
      "DO*: verb 'to do', uninflected present tense or imperative, negated\n",
      "    don't\n",
      "DO+PPSS: verb 'to do', past or present tense + pronoun, personal, nominative, not 3rd person singular\n",
      "    d'you\n",
      "DOD: verb 'to do', past tense\n",
      "    did done\n",
      "DOD*: verb 'to do', past tense, negated\n",
      "    didn't\n",
      "DOZ: verb 'to do', present tense, 3rd person singular\n",
      "    does\n",
      "DOZ*: verb 'to do', present tense, 3rd person singular, negated\n",
      "    doesn't don't\n",
      "DT: determiner/pronoun, singular\n",
      "    this each another that 'nother\n",
      "DT$: determiner/pronoun, singular, genitive\n",
      "    another's\n",
      "DT+BEZ: determiner/pronoun + verb 'to be', present tense, 3rd person singular\n",
      "    that's\n",
      "DT+MD: determiner/pronoun + modal auxillary\n",
      "    that'll this'll\n",
      "DTI: determiner/pronoun, singular or plural\n",
      "    any some\n",
      "DTS: determiner/pronoun, plural\n",
      "    these those them\n",
      "DTS+BEZ: pronoun, plural + verb 'to be', present tense, 3rd person singular\n",
      "    them's\n",
      "DTX: determiner, pronoun or double conjunction\n",
      "    neither either one\n",
      "EX: existential there\n",
      "    there\n",
      "EX+BEZ: existential there + verb 'to be', present tense, 3rd person singular\n",
      "    there's\n",
      "EX+HVD: existential there + verb 'to have', past tense\n",
      "    there'd\n",
      "EX+HVZ: existential there + verb 'to have', present tense, 3rd person singular\n",
      "    there's\n",
      "EX+MD: existential there + modal auxillary\n",
      "    there'll there'd\n",
      "FW-*: foreign word: negator\n",
      "    pas non ne\n",
      "FW-AT: foreign word: article\n",
      "    la le el un die der ein keine eine das las les Il\n",
      "FW-AT+NN: foreign word: article + noun, singular, common\n",
      "    l'orchestre l'identite l'arcade l'ange l'assistance l'activite\n",
      "    L'Universite l'independance L'Union L'Unita l'osservatore\n",
      "FW-AT+NP: foreign word: article + noun, singular, proper\n",
      "    L'Astree L'Imperiale\n",
      "FW-BE: foreign word: verb 'to be', infinitive or imperative\n",
      "    sit\n",
      "FW-BER: foreign word: verb 'to be', present tense, 2nd person singular or all persons plural\n",
      "    sind sunt etes\n",
      "FW-BEZ: foreign word: verb 'to be', present tense, 3rd person singular\n",
      "    ist est\n",
      "FW-CC: foreign word: conjunction, coordinating\n",
      "    et ma mais und aber och nec y\n",
      "FW-CD: foreign word: numeral, cardinal\n",
      "    une cinq deux sieben unam zwei\n",
      "FW-CS: foreign word: conjunction, subordinating\n",
      "    bevor quam ma\n",
      "FW-DT: foreign word: determiner/pronoun, singular\n",
      "    hoc\n",
      "FW-DT+BEZ: foreign word: determiner + verb 'to be', present tense, 3rd person singular\n",
      "    c'est\n",
      "FW-DTS: foreign word: determiner/pronoun, plural\n",
      "    haec\n",
      "FW-HV: foreign word: verb 'to have', present tense, not 3rd person singular\n",
      "    habe\n",
      "FW-IN: foreign word: preposition\n",
      "    ad de en a par con dans ex von auf super post sine sur sub avec per\n",
      "    inter sans pour pendant in di\n",
      "FW-IN+AT: foreign word: preposition + article\n",
      "    della des du aux zur d'un del dell'\n",
      "FW-IN+NN: foreign word: preposition + noun, singular, common\n",
      "    d'etat d'hotel d'argent d'identite d'art\n",
      "FW-IN+NP: foreign word: preposition + noun, singular, proper\n",
      "    d'Yquem d'Eiffel\n",
      "FW-JJ: foreign word: adjective\n",
      "    avant Espagnol sinfonica Siciliana Philharmonique grand publique haute\n",
      "    noire bouffe Douce meme humaine bel serieuses royaux anticus presto\n",
      "    Sovietskaya Bayerische comique schwarzen ...\n",
      "FW-JJR: foreign word: adjective, comparative\n",
      "    fortiori\n",
      "FW-JJT: foreign word: adjective, superlative\n",
      "    optimo\n",
      "FW-NN: foreign word: noun, singular, common\n",
      "    ballet esprit ersatz mano chatte goutte sang Fledermaus oud def kolkhoz\n",
      "    roi troika canto boite blutwurst carne muzyka bonheur monde piece force\n",
      "    ...\n",
      "FW-NN$: foreign word: noun, singular, common, genitive\n",
      "    corporis intellectus arte's dei aeternitatis senioritatis curiae\n",
      "    patronne's chambre's\n",
      "FW-NNS: foreign word: noun, plural, common\n",
      "    al culpas vopos boites haflis kolkhozes augen tyrannis alpha-beta-\n",
      "    gammas metis banditos rata phis negociants crus Einsatzkommandos\n",
      "    kamikaze wohaws sabinas zorrillas palazzi engages coureurs corroborees\n",
      "    yori Ubermenschen ...\n",
      "FW-NP: foreign word: noun, singular, proper\n",
      "    Karshilama Dieu Rundfunk Afrique Espanol Afrika Spagna Gott Carthago\n",
      "    deus\n",
      "FW-NPS: foreign word: noun, plural, proper\n",
      "    Svenskarna Atlantes Dieux\n",
      "FW-NR: foreign word: noun, singular, adverbial\n",
      "    heute morgen aujourd'hui hoy\n",
      "FW-OD: foreign word: numeral, ordinal\n",
      "    18e 17e quintus\n",
      "FW-PN: foreign word: pronoun, nominal\n",
      "    hoc\n",
      "FW-PP$: foreign word: determiner, possessive\n",
      "    mea mon deras vos\n",
      "FW-PPL: foreign word: pronoun, singular, reflexive\n",
      "    se\n",
      "FW-PPL+VBZ: foreign word: pronoun, singular, reflexive + verb, present tense, 3rd person singular\n",
      "    s'excuse s'accuse\n",
      "FW-PPO: pronoun, personal, accusative\n",
      "    lui me moi mi\n",
      "FW-PPO+IN: foreign word: pronoun, personal, accusative + preposition\n",
      "    mecum tecum\n",
      "FW-PPS: foreign word: pronoun, personal, nominative, 3rd person singular\n",
      "    il\n",
      "FW-PPSS: foreign word: pronoun, personal, nominative, not 3rd person singular\n",
      "    ich vous sie je\n",
      "FW-PPSS+HV: foreign word: pronoun, personal, nominative, not 3rd person singular + verb 'to have', present tense, not 3rd person singular\n",
      "    j'ai\n",
      "FW-QL: foreign word: qualifier\n",
      "    minus\n",
      "FW-RB: foreign word: adverb\n",
      "    bas assai deja um wiederum cito velociter vielleicht simpliciter non zu\n",
      "    domi nuper sic forsan olim oui semper tout despues hors\n",
      "FW-RB+CC: foreign word: adverb + conjunction, coordinating\n",
      "    forisque\n",
      "FW-TO+VB: foreign word: infinitival to + verb, infinitive\n",
      "    d'entretenir\n",
      "FW-UH: foreign word: interjection\n",
      "    sayonara bien adieu arigato bonjour adios bueno tchalo ciao o\n",
      "FW-VB: foreign word: verb, present tense, not 3rd person singular, imperative or infinitive\n",
      "    nolo contendere vive fermate faciunt esse vade noli tangere dites duces\n",
      "    meminisse iuvabit gosaimasu voulez habla ksu'u'peli'afo lacheln miuchi\n",
      "    say allons strafe portant\n",
      "FW-VBD: foreign word: verb, past tense\n",
      "    stabat peccavi audivi\n",
      "FW-VBG: foreign word: verb, present participle or gerund\n",
      "    nolens volens appellant seq. obliterans servanda dicendi delenda\n",
      "FW-VBN: foreign word: verb, past participle\n",
      "    vue verstrichen rasa verboten engages\n",
      "FW-VBZ: foreign word: verb, present tense, 3rd person singular\n",
      "    gouverne sinkt sigue diapiace\n",
      "FW-WDT: foreign word: WH-determiner\n",
      "    quo qua quod que quok\n",
      "FW-WPO: foreign word: WH-pronoun, accusative\n",
      "    quibusdam\n",
      "FW-WPS: foreign word: WH-pronoun, nominative\n",
      "    qui\n",
      "HV: verb 'to have', uninflected present tense, infinitive or imperative\n",
      "    have hast\n",
      "HV*: verb 'to have', uninflected present tense or imperative, negated\n",
      "    haven't ain't\n",
      "HV+TO: verb 'to have', uninflected present tense + infinitival to\n",
      "    hafta\n",
      "HVD: verb 'to have', past tense\n",
      "    had\n",
      "HVD*: verb 'to have', past tense, negated\n",
      "    hadn't\n",
      "HVG: verb 'to have', present participle or gerund\n",
      "    having\n",
      "HVN: verb 'to have', past participle\n",
      "    had\n",
      "HVZ: verb 'to have', present tense, 3rd person singular\n",
      "    has hath\n",
      "HVZ*: verb 'to have', present tense, 3rd person singular, negated\n",
      "    hasn't ain't\n",
      "IN: preposition\n",
      "    of in for by considering to on among at through with under into\n",
      "    regarding than since despite according per before toward against as\n",
      "    after during including between without except upon out over ...\n",
      "IN+IN: preposition, hyphenated pair\n",
      "    f'ovuh\n",
      "IN+PPO: preposition + pronoun, personal, accusative\n",
      "    t'hi-im\n",
      "JJ: adjective\n",
      "    ecent over-all possible hard-fought favorable hard meager fit such\n",
      "    widespread outmoded inadequate ambiguous grand clerical effective\n",
      "    orderly federal foster general proportionate ...\n",
      "JJ$: adjective, genitive\n",
      "    Great's\n",
      "JJ+JJ: adjective, hyphenated pair\n",
      "    big-large long-far\n",
      "JJR: adjective, comparative\n",
      "    greater older further earlier later freer franker wider better deeper\n",
      "    firmer tougher faster higher bigger worse younger lighter nicer slower\n",
      "    happier frothier Greater newer Elder ...\n",
      "JJR+CS: adjective + conjunction, coordinating\n",
      "    lighter'n\n",
      "JJS: adjective, semantically superlative\n",
      "    top chief principal northernmost master key head main tops utmost\n",
      "    innermost foremost uppermost paramount topmost\n",
      "JJT: adjective, superlative\n",
      "    best largest coolest calmest latest greatest earliest simplest\n",
      "    strongest newest fiercest unhappiest worst youngest worthiest fastest\n",
      "    hottest fittest lowest finest smallest staunchest ...\n",
      "MD: modal auxillary\n",
      "    should may might will would must can could shall ought need wilt\n",
      "MD*: modal auxillary, negated\n",
      "    cannot couldn't wouldn't can't won't shouldn't shan't mustn't musn't\n",
      "MD+HV: modal auxillary + verb 'to have', uninflected form\n",
      "    shouldda musta coulda must've woulda could've\n",
      "MD+PPSS: modal auxillary + pronoun, personal, nominative, not 3rd person singular\n",
      "    willya\n",
      "MD+TO: modal auxillary + infinitival to\n",
      "    oughta\n",
      "NN: noun, singular, common\n",
      "    failure burden court fire appointment awarding compensation Mayor\n",
      "    interim committee fact effect airport management surveillance jail\n",
      "    doctor intern extern night weekend duty legislation Tax Office ...\n",
      "NN$: noun, singular, common, genitive\n",
      "    season's world's player's night's chapter's golf's football's\n",
      "    baseball's club's U.'s coach's bride's bridegroom's board's county's\n",
      "    firm's company's superintendent's mob's Navy's ...\n",
      "NN+BEZ: noun, singular, common + verb 'to be', present tense, 3rd person singular\n",
      "    water's camera's sky's kid's Pa's heat's throat's father's money's\n",
      "    undersecretary's granite's level's wife's fat's Knife's fire's name's\n",
      "    hell's leg's sun's roulette's cane's guy's kind's baseball's ...\n",
      "NN+HVD: noun, singular, common + verb 'to have', past tense\n",
      "    Pa'd\n",
      "NN+HVZ: noun, singular, common + verb 'to have', present tense, 3rd person singular\n",
      "    guy's Knife's boat's summer's rain's company's\n",
      "NN+IN: noun, singular, common + preposition\n",
      "    buncha\n",
      "NN+MD: noun, singular, common + modal auxillary\n",
      "    cowhand'd sun'll\n",
      "NN+NN: noun, singular, common, hyphenated pair\n",
      "    stomach-belly\n",
      "NNS: noun, plural, common\n",
      "    irregularities presentments thanks reports voters laws legislators\n",
      "    years areas adjustments chambers $100 bonds courts sales details raises\n",
      "    sessions members congressmen votes polls calls ...\n",
      "NNS$: noun, plural, common, genitive\n",
      "    taxpayers' children's members' States' women's cutters' motorists'\n",
      "    steelmakers' hours' Nations' lawyers' prisoners' architects' tourists'\n",
      "    Employers' secretaries' Rogues' ...\n",
      "NNS+MD: noun, plural, common + modal auxillary\n",
      "    duds'd oystchers'll\n",
      "NP: noun, singular, proper\n",
      "    Fulton Atlanta September-October Durwood Pye Ivan Allen Jr. Jan.\n",
      "    Alpharetta Grady William B. Hartsfield Pearl Williams Aug. Berry J. M.\n",
      "    Cheshire Griffin Opelika Ala. E. Pelham Snodgrass ...\n",
      "NP$: noun, singular, proper, genitive\n",
      "    Green's Landis' Smith's Carreon's Allison's Boston's Spahn's Willie's\n",
      "    Mickey's Milwaukee's Mays' Howsam's Mantle's Shaw's Wagner's Rickey's\n",
      "    Shea's Palmer's Arnold's Broglio's ...\n",
      "NP+BEZ: noun, singular, proper + verb 'to be', present tense, 3rd person singular\n",
      "    W.'s Ike's Mack's Jack's Kate's Katharine's Black's Arthur's Seaton's\n",
      "    Buckhorn's Breed's Penny's Rob's Kitty's Blackwell's Myra's Wally's\n",
      "    Lucille's Springfield's Arlene's\n",
      "NP+HVZ: noun, singular, proper + verb 'to have', present tense, 3rd person singular\n",
      "    Bill's Guardino's Celie's Skolman's Crosson's Tim's Wally's\n",
      "NP+MD: noun, singular, proper + modal auxillary\n",
      "    Gyp'll John'll\n",
      "NPS: noun, plural, proper\n",
      "    Chases Aderholds Chapelles Armisteads Lockies Carbones French Marskmen\n",
      "    Toppers Franciscans Romans Cadillacs Masons Blacks Catholics British\n",
      "    Dixiecrats Mississippians Congresses ...\n",
      "NPS$: noun, plural, proper, genitive\n",
      "    Republicans' Orioles' Birds' Yanks' Redbirds' Bucs' Yankees' Stevenses'\n",
      "    Geraghtys' Burkes' Wackers' Achaeans' Dresbachs' Russians' Democrats'\n",
      "    Gershwins' Adventists' Negroes' Catholics' ...\n",
      "NR: noun, singular, adverbial\n",
      "    Friday home Wednesday Tuesday Monday Sunday Thursday yesterday tomorrow\n",
      "    tonight West East Saturday west left east downtown north northeast\n",
      "    southeast northwest North South right ...\n",
      "NR$: noun, singular, adverbial, genitive\n",
      "    Saturday's Monday's yesterday's tonight's tomorrow's Sunday's\n",
      "    Wednesday's Friday's today's Tuesday's West's Today's South's\n",
      "NR+MD: noun, singular, adverbial + modal auxillary\n",
      "    today'll\n",
      "NRS: noun, plural, adverbial\n",
      "    Sundays Mondays Saturdays Wednesdays Souths Fridays\n",
      "OD: numeral, ordinal\n",
      "    first 13th third nineteenth 2d 61st second sixth eighth ninth twenty-\n",
      "    first eleventh 50th eighteenth- Thirty-ninth 72nd 1/20th twentieth\n",
      "    mid-19th thousandth 350th sixteenth 701st ...\n",
      "PN: pronoun, nominal\n",
      "    none something everything one anyone nothing nobody everybody everyone\n",
      "    anybody anything someone no-one nothin\n",
      "PN$: pronoun, nominal, genitive\n",
      "    one's someone's anybody's nobody's everybody's anyone's everyone's\n",
      "PN+BEZ: pronoun, nominal + verb 'to be', present tense, 3rd person singular\n",
      "    nothing's everything's somebody's nobody's someone's\n",
      "PN+HVD: pronoun, nominal + verb 'to have', past tense\n",
      "    nobody'd\n",
      "PN+HVZ: pronoun, nominal + verb 'to have', present tense, 3rd person singular\n",
      "    nobody's somebody's one's\n",
      "PN+MD: pronoun, nominal + modal auxillary\n",
      "    someone'll somebody'll anybody'd\n",
      "PP$: determiner, possessive\n",
      "    our its his their my your her out thy mine thine\n",
      "PP$$: pronoun, possessive\n",
      "    ours mine his hers theirs yours\n",
      "PPL: pronoun, singular, reflexive\n",
      "    itself himself myself yourself herself oneself ownself\n",
      "PPLS: pronoun, plural, reflexive\n",
      "    themselves ourselves yourselves\n",
      "PPO: pronoun, personal, accusative\n",
      "    them it him me us you 'em her thee we'uns\n",
      "PPS: pronoun, personal, nominative, 3rd person singular\n",
      "    it he she thee\n",
      "PPS+BEZ: pronoun, personal, nominative, 3rd person singular + verb 'to be', present tense, 3rd person singular\n",
      "    it's he's she's\n",
      "PPS+HVD: pronoun, personal, nominative, 3rd person singular + verb 'to have', past tense\n",
      "    she'd he'd it'd\n",
      "PPS+HVZ: pronoun, personal, nominative, 3rd person singular + verb 'to have', present tense, 3rd person singular\n",
      "    it's he's she's\n",
      "PPS+MD: pronoun, personal, nominative, 3rd person singular + modal auxillary\n",
      "    he'll she'll it'll he'd it'd she'd\n",
      "PPSS: pronoun, personal, nominative, not 3rd person singular\n",
      "    they we I you ye thou you'uns\n",
      "PPSS+BEM: pronoun, personal, nominative, not 3rd person singular + verb 'to be', present tense, 1st person singular\n",
      "    I'm Ahm\n",
      "PPSS+BER: pronoun, personal, nominative, not 3rd person singular + verb 'to be', present tense, 2nd person singular or all persons plural\n",
      "    we're you're they're\n",
      "PPSS+BEZ: pronoun, personal, nominative, not 3rd person singular + verb 'to be', present tense, 3rd person singular\n",
      "    you's\n",
      "PPSS+BEZ*: pronoun, personal, nominative, not 3rd person singular + verb 'to be', present tense, 3rd person singular, negated\n",
      "    'tain't\n",
      "PPSS+HV: pronoun, personal, nominative, not 3rd person singular + verb 'to have', uninflected present tense\n",
      "    I've we've they've you've\n",
      "PPSS+HVD: pronoun, personal, nominative, not 3rd person singular + verb 'to have', past tense\n",
      "    I'd you'd we'd they'd\n",
      "PPSS+MD: pronoun, personal, nominative, not 3rd person singular + modal auxillary\n",
      "    you'll we'll I'll we'd I'd they'll they'd you'd\n",
      "PPSS+VB: pronoun, personal, nominative, not 3rd person singular + verb 'to verb', uninflected present tense\n",
      "    y'know\n",
      "QL: qualifier, pre\n",
      "    well less very most so real as highly fundamentally even how much\n",
      "    remarkably somewhat more completely too thus ill deeply little overly\n",
      "    halfway almost impossibly far severly such ...\n",
      "QLP: qualifier, post\n",
      "    indeed enough still 'nuff\n",
      "RB: adverb\n",
      "    only often generally also nevertheless upon together back newly no\n",
      "    likely meanwhile near then heavily there apparently yet outright fully\n",
      "    aside consistently specifically formally ever just ...\n",
      "RB$: adverb, genitive\n",
      "    else's\n",
      "RB+BEZ: adverb + verb 'to be', present tense, 3rd person singular\n",
      "    here's there's\n",
      "RB+CS: adverb + conjunction, coordinating\n",
      "    well's soon's\n",
      "RBR: adverb, comparative\n",
      "    further earlier better later higher tougher more harder longer sooner\n",
      "    less faster easier louder farther oftener nearer cheaper slower tighter\n",
      "    lower worse heavier quicker ...\n",
      "RBR+CS: adverb, comparative + conjunction, coordinating\n",
      "    more'n\n",
      "RBT: adverb, superlative\n",
      "    most best highest uppermost nearest brightest hardest fastest deepest\n",
      "    farthest loudest ...\n",
      "RN: adverb, nominal\n",
      "    here afar then\n",
      "RP: adverb, particle\n",
      "    up out off down over on in about through across after\n",
      "RP+IN: adverb, particle + preposition\n",
      "    out'n outta\n",
      "TO: infinitival to\n",
      "    to t'\n",
      "TO+VB: infinitival to + verb, infinitive\n",
      "    t'jawn t'lah\n",
      "UH: interjection\n",
      "    Hurrah bang whee hmpf ah goodbye oops oh-the-pain-of-it ha crunch say\n",
      "    oh why see well hello lo alas tarantara rum-tum-tum gosh hell keerist\n",
      "    Jesus Keeeerist boy c'mon 'mon goddamn bah hoo-pig damn ...\n",
      "VB: verb, base: uninflected present, imperative or infinitive\n",
      "    investigate find act follow inure achieve reduce take remedy re-set\n",
      "    distribute realize disable feel receive continue place protect\n",
      "    eliminate elaborate work permit run enter force ...\n",
      "VB+AT: verb, base: uninflected present or infinitive + article\n",
      "    wanna\n",
      "VB+IN: verb, base: uninflected present, imperative or infinitive + preposition\n",
      "    lookit\n",
      "VB+JJ: verb, base: uninflected present, imperative or infinitive + adjective\n",
      "    die-dead\n",
      "VB+PPO: verb, uninflected present tense + pronoun, personal, accusative\n",
      "    let's lemme gimme\n",
      "VB+RP: verb, imperative + adverbial particle\n",
      "    g'ahn c'mon\n",
      "VB+TO: verb, base: uninflected present, imperative or infinitive + infinitival to\n",
      "    wanta wanna\n",
      "VB+VB: verb, base: uninflected present, imperative or infinitive; hypenated pair\n",
      "    say-speak\n",
      "VBD: verb, past tense\n",
      "    said produced took recommended commented urged found added praised\n",
      "    charged listed became announced brought attended wanted voted defeated\n",
      "    received got stood shot scheduled feared promised made ...\n",
      "VBG: verb, present participle or gerund\n",
      "    modernizing improving purchasing Purchasing lacking enabling pricing\n",
      "    keeping getting picking entering voting warning making strengthening\n",
      "    setting neighboring attending participating moving ...\n",
      "VBG+TO: verb, present participle + infinitival to\n",
      "    gonna\n",
      "VBN: verb, past participle\n",
      "    conducted charged won received studied revised operated accepted\n",
      "    combined experienced recommended effected granted seen protected\n",
      "    adopted retarded notarized selected composed gotten printed ...\n",
      "VBN+TO: verb, past participle + infinitival to\n",
      "    gotta\n",
      "VBZ: verb, present tense, 3rd person singular\n",
      "    deserves believes receives takes goes expires says opposes starts\n",
      "    permits expects thinks faces votes teaches holds calls fears spends\n",
      "    collects backs eliminates sets flies gives seeks reads ...\n",
      "WDT: WH-determiner\n",
      "    which what whatever whichever whichever-the-hell\n",
      "WDT+BER: WH-determiner + verb 'to be', present tense, 2nd person singular or all persons plural\n",
      "    what're\n",
      "WDT+BER+PP: WH-determiner + verb 'to be', present, 2nd person singular or all persons plural + pronoun, personal, nominative, not 3rd person singular\n",
      "    whaddya\n",
      "WDT+BEZ: WH-determiner + verb 'to be', present tense, 3rd person singular\n",
      "    what's\n",
      "WDT+DO+PPS: WH-determiner + verb 'to do', uninflected present tense + pronoun, personal, nominative, not 3rd person singular\n",
      "    whaddya\n",
      "WDT+DOD: WH-determiner + verb 'to do', past tense\n",
      "    what'd\n",
      "WDT+HVZ: WH-determiner + verb 'to have', present tense, 3rd person singular\n",
      "    what's\n",
      "WP$: WH-pronoun, genitive\n",
      "    whose whosever\n",
      "WPO: WH-pronoun, accusative\n",
      "    whom that who\n",
      "WPS: WH-pronoun, nominative\n",
      "    that who whoever whosoever what whatsoever\n",
      "WPS+BEZ: WH-pronoun, nominative + verb 'to be', present, 3rd person singular\n",
      "    that's who's\n",
      "WPS+HVD: WH-pronoun, nominative + verb 'to have', past tense\n",
      "    who'd\n",
      "WPS+HVZ: WH-pronoun, nominative + verb 'to have', present tense, 3rd person singular\n",
      "    who's that's\n",
      "WPS+MD: WH-pronoun, nominative + modal auxillary\n",
      "    who'll that'd who'd that'll\n",
      "WQL: WH-qualifier\n",
      "    however how\n",
      "WRB: WH-adverb\n",
      "    however when where why whereby wherever how whenever whereon wherein\n",
      "    wherewith wheare wherefore whereof howsabout\n",
      "WRB+BER: WH-adverb + verb 'to be', present, 2nd person singular or all persons plural\n",
      "    where're\n",
      "WRB+BEZ: WH-adverb + verb 'to be', present, 3rd person singular\n",
      "    how's where's\n",
      "WRB+DO: WH-adverb + verb 'to do', present, not 3rd person singular\n",
      "    howda\n",
      "WRB+DOD: WH-adverb + verb 'to do', past tense\n",
      "    where'd how'd\n",
      "WRB+DOD*: WH-adverb + verb 'to do', past tense, negated\n",
      "    whyn't\n",
      "WRB+DOZ: WH-adverb + verb 'to do', present tense, 3rd person singular\n",
      "    how's\n",
      "WRB+IN: WH-adverb + preposition\n",
      "    why'n\n",
      "WRB+MD: WH-adverb + modal auxillary\n",
      "    where'd\n"
     ]
    }
   ],
   "source": [
    "nltk.help.brown_tagset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['adventure',\n",
       " 'belles_lettres',\n",
       " 'editorial',\n",
       " 'fiction',\n",
       " 'government',\n",
       " 'hobbies',\n",
       " 'humor',\n",
       " 'learned',\n",
       " 'lore',\n",
       " 'mystery',\n",
       " 'news',\n",
       " 'religion',\n",
       " 'reviews',\n",
       " 'romance',\n",
       " 'science_fiction']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "brown.categories()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['The', 'Fulton', 'County', 'Grand', 'Jury', 'said', ...]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "brown.words(categories='news')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = \"\"\"In the morning Frodo woke refreshed. He was lying in a bower made by a living tree with branches laced and drooping to the ground; his bed was of fern and grass, deep and soft and strangely fragrant. The sun was shining through the fluttering leaves, which were still green upon the tree. He jumped up and went out. Sam was sitting on the grass near the edge of the wood. Pippin was standing studying the sky and weather. There was no sign of the Elves. ‘They have left us fruit and drink, and bread,’ said Pippin. ‘Come and have your breakfast. The bread tastes almost as good as it did last night. I did not want to leave you any, but Sam insisted.’\"\"\"\n",
    "\n",
    "data_words = word_tokenize(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['In',\n",
       " 'the',\n",
       " 'morning',\n",
       " 'Frodo',\n",
       " 'woke',\n",
       " 'refreshed',\n",
       " '.',\n",
       " 'He',\n",
       " 'was',\n",
       " 'lying',\n",
       " 'in',\n",
       " 'a',\n",
       " 'bower',\n",
       " 'made',\n",
       " 'by',\n",
       " 'a',\n",
       " 'living',\n",
       " 'tree',\n",
       " 'with',\n",
       " 'branches',\n",
       " 'laced',\n",
       " 'and',\n",
       " 'drooping',\n",
       " 'to',\n",
       " 'the',\n",
       " 'ground',\n",
       " ';',\n",
       " 'his',\n",
       " 'bed',\n",
       " 'was',\n",
       " 'of',\n",
       " 'fern',\n",
       " 'and',\n",
       " 'grass',\n",
       " ',',\n",
       " 'deep',\n",
       " 'and',\n",
       " 'soft',\n",
       " 'and',\n",
       " 'strangely',\n",
       " 'fragrant',\n",
       " '.',\n",
       " 'The',\n",
       " 'sun',\n",
       " 'was',\n",
       " 'shining',\n",
       " 'through',\n",
       " 'the',\n",
       " 'fluttering',\n",
       " 'leaves',\n",
       " ',',\n",
       " 'which',\n",
       " 'were',\n",
       " 'still',\n",
       " 'green',\n",
       " 'upon',\n",
       " 'the',\n",
       " 'tree',\n",
       " '.',\n",
       " 'He',\n",
       " 'jumped',\n",
       " 'up',\n",
       " 'and',\n",
       " 'went',\n",
       " 'out',\n",
       " '.',\n",
       " 'Sam',\n",
       " 'was',\n",
       " 'sitting',\n",
       " 'on',\n",
       " 'the',\n",
       " 'grass',\n",
       " 'near',\n",
       " 'the',\n",
       " 'edge',\n",
       " 'of',\n",
       " 'the',\n",
       " 'wood',\n",
       " '.',\n",
       " 'Pippin',\n",
       " 'was',\n",
       " 'standing',\n",
       " 'studying',\n",
       " 'the',\n",
       " 'sky',\n",
       " 'and',\n",
       " 'weather',\n",
       " '.',\n",
       " 'There',\n",
       " 'was',\n",
       " 'no',\n",
       " 'sign',\n",
       " 'of',\n",
       " 'the',\n",
       " 'Elves',\n",
       " '.',\n",
       " '‘',\n",
       " 'They',\n",
       " 'have',\n",
       " 'left',\n",
       " 'us',\n",
       " 'fruit',\n",
       " 'and',\n",
       " 'drink',\n",
       " ',',\n",
       " 'and',\n",
       " 'bread',\n",
       " ',',\n",
       " '’',\n",
       " 'said',\n",
       " 'Pippin',\n",
       " '.',\n",
       " '‘',\n",
       " 'Come',\n",
       " 'and',\n",
       " 'have',\n",
       " 'your',\n",
       " 'breakfast',\n",
       " '.',\n",
       " 'The',\n",
       " 'bread',\n",
       " 'tastes',\n",
       " 'almost',\n",
       " 'as',\n",
       " 'good',\n",
       " 'as',\n",
       " 'it',\n",
       " 'did',\n",
       " 'last',\n",
       " 'night',\n",
       " '.',\n",
       " 'I',\n",
       " 'did',\n",
       " 'not',\n",
       " 'want',\n",
       " 'to',\n",
       " 'leave',\n",
       " 'you',\n",
       " 'any',\n",
       " ',',\n",
       " 'but',\n",
       " 'Sam',\n",
       " 'insisted',\n",
       " '.',\n",
       " '’']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "145"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import sent_tokenize\n",
    "data_sent = sent_tokenize(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['In the morning Frodo woke refreshed.',\n",
       " 'He was lying in a bower made by a living tree with branches laced and drooping to the ground; his bed was of fern and grass, deep and soft and strangely fragrant.',\n",
       " 'The sun was shining through the fluttering leaves, which were still green upon the tree.',\n",
       " 'He jumped up and went out.',\n",
       " 'Sam was sitting on the grass near the edge of the wood.',\n",
       " 'Pippin was standing studying the sky and weather.',\n",
       " 'There was no sign of the Elves.',\n",
       " '‘They have left us fruit and drink, and bread,’ said Pippin.',\n",
       " '‘Come and have your breakfast.',\n",
       " 'The bread tastes almost as good as it did last night.',\n",
       " 'I did not want to leave you any, but Sam insisted.’']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_sent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data_sent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'In the morning Frodo woke refreshed.'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_sent[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk import pos_tag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_tag = pos_tag(data_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('In', 'IN'),\n",
       " ('the', 'DT'),\n",
       " ('morning', 'NN'),\n",
       " ('Frodo', 'NNP'),\n",
       " ('woke', 'VBD'),\n",
       " ('refreshed', 'VBN'),\n",
       " ('.', '.'),\n",
       " ('He', 'PRP'),\n",
       " ('was', 'VBD'),\n",
       " ('lying', 'VBG'),\n",
       " ('in', 'IN'),\n",
       " ('a', 'DT'),\n",
       " ('bower', 'NN'),\n",
       " ('made', 'VBN'),\n",
       " ('by', 'IN'),\n",
       " ('a', 'DT'),\n",
       " ('living', 'NN'),\n",
       " ('tree', 'NN'),\n",
       " ('with', 'IN'),\n",
       " ('branches', 'NNS'),\n",
       " ('laced', 'VBN'),\n",
       " ('and', 'CC'),\n",
       " ('drooping', 'VBG'),\n",
       " ('to', 'TO'),\n",
       " ('the', 'DT'),\n",
       " ('ground', 'NN'),\n",
       " (';', ':'),\n",
       " ('his', 'PRP$'),\n",
       " ('bed', 'NN'),\n",
       " ('was', 'VBD'),\n",
       " ('of', 'IN'),\n",
       " ('fern', 'JJ'),\n",
       " ('and', 'CC'),\n",
       " ('grass', 'NN'),\n",
       " (',', ','),\n",
       " ('deep', 'JJ'),\n",
       " ('and', 'CC'),\n",
       " ('soft', 'JJ'),\n",
       " ('and', 'CC'),\n",
       " ('strangely', 'RB'),\n",
       " ('fragrant', 'JJ'),\n",
       " ('.', '.'),\n",
       " ('The', 'DT'),\n",
       " ('sun', 'NN'),\n",
       " ('was', 'VBD'),\n",
       " ('shining', 'VBG'),\n",
       " ('through', 'IN'),\n",
       " ('the', 'DT'),\n",
       " ('fluttering', 'NN'),\n",
       " ('leaves', 'NNS'),\n",
       " (',', ','),\n",
       " ('which', 'WDT'),\n",
       " ('were', 'VBD'),\n",
       " ('still', 'RB'),\n",
       " ('green', 'JJ'),\n",
       " ('upon', 'IN'),\n",
       " ('the', 'DT'),\n",
       " ('tree', 'NN'),\n",
       " ('.', '.'),\n",
       " ('He', 'PRP'),\n",
       " ('jumped', 'VBD'),\n",
       " ('up', 'RB'),\n",
       " ('and', 'CC'),\n",
       " ('went', 'VBD'),\n",
       " ('out', 'RP'),\n",
       " ('.', '.'),\n",
       " ('Sam', 'NNP'),\n",
       " ('was', 'VBD'),\n",
       " ('sitting', 'VBG'),\n",
       " ('on', 'IN'),\n",
       " ('the', 'DT'),\n",
       " ('grass', 'NN'),\n",
       " ('near', 'IN'),\n",
       " ('the', 'DT'),\n",
       " ('edge', 'NN'),\n",
       " ('of', 'IN'),\n",
       " ('the', 'DT'),\n",
       " ('wood', 'NN'),\n",
       " ('.', '.'),\n",
       " ('Pippin', 'NNP'),\n",
       " ('was', 'VBD'),\n",
       " ('standing', 'VBG'),\n",
       " ('studying', 'VBG'),\n",
       " ('the', 'DT'),\n",
       " ('sky', 'NN'),\n",
       " ('and', 'CC'),\n",
       " ('weather', 'NN'),\n",
       " ('.', '.'),\n",
       " ('There', 'EX'),\n",
       " ('was', 'VBD'),\n",
       " ('no', 'DT'),\n",
       " ('sign', 'NN'),\n",
       " ('of', 'IN'),\n",
       " ('the', 'DT'),\n",
       " ('Elves', 'NNP'),\n",
       " ('.', '.'),\n",
       " ('‘', 'NN'),\n",
       " ('They', 'PRP'),\n",
       " ('have', 'VBP'),\n",
       " ('left', 'VBN'),\n",
       " ('us', 'PRP'),\n",
       " ('fruit', 'NN'),\n",
       " ('and', 'CC'),\n",
       " ('drink', 'NN'),\n",
       " (',', ','),\n",
       " ('and', 'CC'),\n",
       " ('bread', 'NN'),\n",
       " (',', ','),\n",
       " ('’', 'NNP'),\n",
       " ('said', 'VBD'),\n",
       " ('Pippin', 'NNP'),\n",
       " ('.', '.'),\n",
       " ('‘', 'CC'),\n",
       " ('Come', 'NNP'),\n",
       " ('and', 'CC'),\n",
       " ('have', 'VB'),\n",
       " ('your', 'PRP$'),\n",
       " ('breakfast', 'NN'),\n",
       " ('.', '.'),\n",
       " ('The', 'DT'),\n",
       " ('bread', 'NN'),\n",
       " ('tastes', 'VBZ'),\n",
       " ('almost', 'RB'),\n",
       " ('as', 'RB'),\n",
       " ('good', 'JJ'),\n",
       " ('as', 'IN'),\n",
       " ('it', 'PRP'),\n",
       " ('did', 'VBD'),\n",
       " ('last', 'JJ'),\n",
       " ('night', 'NN'),\n",
       " ('.', '.'),\n",
       " ('I', 'PRP'),\n",
       " ('did', 'VBD'),\n",
       " ('not', 'RB'),\n",
       " ('want', 'VB'),\n",
       " ('to', 'TO'),\n",
       " ('leave', 'VB'),\n",
       " ('you', 'PRP'),\n",
       " ('any', 'DT'),\n",
       " (',', ','),\n",
       " ('but', 'CC'),\n",
       " ('Sam', 'NNP'),\n",
       " ('insisted', 'VBD'),\n",
       " ('.', '.'),\n",
       " ('’', 'NN')]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_tag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['IN', 'DT', 'NN', 'NNP', 'VBD', 'VBN', '.', 'PRP', 'VBG', 'NNS', 'CC', 'TO', ':', 'PRP$', 'JJ', ',', 'RB', 'WDT', 'RP', 'EX', 'VBP', 'VB', 'VBZ']\n"
     ]
    }
   ],
   "source": [
    "list = []\n",
    "for i in range(len(data_tag)):    \n",
    "    if data_tag[i][1] not in list:\n",
    "        list.append(data_tag[i][1])\n",
    "print(list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.probability import FreqDist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('NN', 24),\n",
       " ('DT', 15),\n",
       " ('VBD', 14),\n",
       " ('IN', 12),\n",
       " ('.', 11),\n",
       " ('CC', 11),\n",
       " ('NNP', 8),\n",
       " ('PRP', 7),\n",
       " ('JJ', 7),\n",
       " ('VBG', 6),\n",
       " ('RB', 6),\n",
       " (',', 5),\n",
       " ('VBN', 4),\n",
       " ('VB', 3),\n",
       " ('NNS', 2),\n",
       " ('TO', 2),\n",
       " ('PRP$', 2),\n",
       " (':', 1),\n",
       " ('WDT', 1),\n",
       " ('RP', 1),\n",
       " ('EX', 1),\n",
       " ('VBP', 1),\n",
       " ('VBZ', 1)]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tag_freq = FreqDist(tag for (word, tag) in data_tag)\n",
    "tag_freq.most_common()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import PorterStemmer\n",
    "porter_stemmer = PorterStemmer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In : In\n",
      "the : the\n",
      "morning : morn\n",
      "Frodo : frodo\n",
      "woke : woke\n",
      "refreshed : refresh\n",
      ". : .\n",
      "He : He\n",
      "was : wa\n",
      "lying : lie\n",
      "in : in\n",
      "a : a\n",
      "bower : bower\n",
      "made : made\n",
      "by : by\n",
      "a : a\n",
      "living : live\n",
      "tree : tree\n",
      "with : with\n",
      "branches : branch\n"
     ]
    }
   ],
   "source": [
    "for word in data_words[0:20]:\n",
    "    print(word+\" : \"+porter_stemmer.stem(word))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "word_net_lem = WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "plurals = \"alligators cars fishes beaches children colossi tomatoes dogs theses phenomena analyses witches\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "plurals = word_tokenize(plurals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['alligators',\n",
       " 'cars',\n",
       " 'fishes',\n",
       " 'beaches',\n",
       " 'children',\n",
       " 'colossi',\n",
       " 'tomatoes',\n",
       " 'dogs',\n",
       " 'theses',\n",
       " 'phenomena',\n",
       " 'analyses',\n",
       " 'witches']"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "plurals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "alligators : alligator\n",
      "cars : car\n",
      "fishes : fish\n",
      "beaches : beach\n",
      "children : child\n",
      "colossi : colossus\n",
      "tomatoes : tomato\n",
      "dogs : dog\n",
      "theses : thesis\n",
      "phenomena : phenomenon\n",
      "analyses : analysis\n",
      "witches : witch\n"
     ]
    }
   ],
   "source": [
    "for word in plurals:\n",
    "    print(word + \" : \" + word_net_lem.lemmatize(word))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "# save np.load\n",
    "np_load_old = np.load\n",
    "\n",
    "# modify the default parameters of np.load\n",
    "np.load = lambda *a,**k: np_load_old(*a, allow_pickle=True, **k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.datasets import reuters\n",
    "(x_train, y_train), (x_test, y_test) = reuters.load_data(num_words=None, test_split=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.load = np_load_old"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train class =  <class 'numpy.ndarray'>\n",
      "y_train class =  <class 'numpy.ndarray'>\n",
      "x_test class =  <class 'numpy.ndarray'>\n",
      "y_test class =  <class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "print('x_train class = ', type(x_train))\n",
    "print('y_train class = ', type(y_train))\n",
    "print('x_test class = ', type(x_test))\n",
    "print('y_test class = ', type(y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train shape =  (7859,)\n",
      "y_train shape =  (7859,)\n",
      "x_test shape =  (3369,)\n",
      "y_test shape =  (3369,)\n"
     ]
    }
   ],
   "source": [
    "print('x_train shape = ', x_train.shape)\n",
    "print('y_train shape = ', y_train.shape)\n",
    "print('x_test shape = ', x_test.shape)\n",
    "print('y_test shape = ', y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y_train values =  [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n",
      " 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45]\n",
      "y_test values =  [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n",
      " 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45]\n"
     ]
    }
   ],
   "source": [
    "print('y_train values = ', np.unique(y_train))\n",
    "print('y_test values = ', np.unique(y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y_train distribution =  {0: 50, 1: 378, 2: 66, 3: 2769, 4: 1701, 5: 14, 6: 39, 7: 15, 8: 126, 9: 93, 10: 114, 11: 337, 12: 40, 13: 149, 14: 18, 15: 19, 16: 387, 17: 33, 18: 59, 19: 475, 20: 238, 21: 91, 22: 10, 23: 36, 24: 56, 25: 77, 26: 18, 27: 13, 28: 43, 29: 19, 30: 38, 31: 34, 32: 30, 33: 9, 34: 43, 35: 10, 36: 46, 37: 17, 38: 16, 39: 20, 40: 32, 41: 28, 42: 10, 43: 19, 44: 10, 45: 14}\n",
      "y_test distribution =  {0: 17, 1: 159, 2: 28, 3: 1203, 4: 722, 5: 8, 6: 23, 7: 4, 8: 51, 9: 33, 10: 40, 11: 136, 12: 22, 13: 60, 14: 10, 15: 10, 16: 156, 17: 18, 18: 27, 19: 207, 20: 101, 21: 36, 22: 12, 23: 17, 24: 25, 25: 46, 26: 14, 27: 6, 28: 15, 29: 4, 30: 19, 31: 18, 32: 12, 33: 7, 34: 14, 35: 6, 36: 14, 37: 4, 38: 6, 39: 9, 40: 14, 41: 10, 42: 6, 43: 8, 44: 7, 45: 5}\n"
     ]
    }
   ],
   "source": [
    "unique, counts = np.unique(y_train, return_counts=True)\n",
    "print('y_train distribution = ', dict(zip(unique, counts)))\n",
    "unique, counts = np.unique(y_test, return_counts=True)\n",
    "print('y_test distribution = ', dict(zip(unique, counts)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'y_test Data')"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(1)\n",
    "plt.subplot(121)\n",
    "plt.hist(y_train, bins='auto')\n",
    "plt.xlabel('Classes')\n",
    "plt.ylabel('Number of occurences')\n",
    "plt.title('y_train Data')\n",
    "\n",
    "plt.figure(2)\n",
    "plt.subplot(121)\n",
    "plt.hist(y_test, bins='auto')\n",
    "plt.xlabel('Classes')\n",
    "plt.ylabel('Number of occurences')\n",
    "plt.title('y_test Data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 3267, 699, 3434, 2295, 56, 16784, 7511, 9, 56, 3906, 1073, 81, 5, 1198, 57, 366, 737, 132, 20, 4093, 7, 19261, 49, 2295, 13415, 1037, 3267, 699, 3434, 8, 7, 10, 241, 16, 855, 129, 231, 783, 5, 4, 587, 2295, 13415, 30625, 775, 7, 48, 34, 191, 44, 35, 1795, 505, 17, 12]\n"
     ]
    }
   ],
   "source": [
    "print(x_train[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "56"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(x_train[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30979"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_index = reuters.get_word_index(path='reuters_word_index.json')\n",
    "len(word_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "index_to_word = {}\n",
    "for key, value in word_index.items():\n",
    "    index_to_word[value] = key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the termination payment airport takes 6 visibility geological 3 6 602 begin up said fully bank expects commodity total is giant a recreation this takes leroy series termination payment airport mln a for capital 1 pre 50 american east said in council takes leroy recommend's france a but u any 4 s 1st losses pct dlrs\n"
     ]
    }
   ],
   "source": [
    "print(' '.join([index_to_word[x] for x in x_train[1]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n"
     ]
    }
   ],
   "source": [
    "print(y_train[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.text import Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_words = 10000\n",
    "tokenizer = Tokenizer(num_words=max_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = tokenizer.sequences_to_matrix(x_train, mode='binary')\n",
    "x_test = tokenizer.sequences_to_matrix(x_test, mode='binary')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = max(y_train) + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.utils import to_categorical\n",
    "y_train = to_categorical(y_train, num_classes)\n",
    "y_test = to_categorical(y_test, num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "46"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(y_train[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0929 22:17:14.843474 17376 deprecation_wrapper.py:119] From C:\\Users\\Patryk\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "W0929 22:17:14.855418 17376 deprecation_wrapper.py:119] From C:\\Users\\Patryk\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "W0929 22:17:14.856443 17376 deprecation_wrapper.py:119] From C:\\Users\\Patryk\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n",
      "W0929 22:17:14.868383 17376 deprecation_wrapper.py:119] From C:\\Users\\Patryk\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:133: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n",
      "\n",
      "W0929 22:17:14.873400 17376 deprecation.py:506] From C:\\Users\\Patryk\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n"
     ]
    }
   ],
   "source": [
    "DNN_model = Sequential()\n",
    "DNN_model.add(Dense(512, input_shape=(max_words,)))\n",
    "DNN_model.add(Activation('relu'))\n",
    "DNN_model.add(Dropout(0.5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "DNN_model.add(Dense(num_classes))\n",
    "DNN_model.add(Activation('softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1 (Dense)              (None, 512)               5120512   \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 46)                23598     \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 46)                0         \n",
      "=================================================================\n",
      "Total params: 5,144,110\n",
      "Trainable params: 5,144,110\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "DNN_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0929 22:17:14.910273 17376 deprecation_wrapper.py:119] From C:\\Users\\Patryk\\Anaconda3\\lib\\site-packages\\keras\\optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "W0929 22:17:14.927947 17376 deprecation_wrapper.py:119] From C:\\Users\\Patryk\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:3295: The name tf.log is deprecated. Please use tf.math.log instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "DNN_model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0929 22:17:15.014741 17376 deprecation.py:323] From C:\\Users\\Patryk\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\math_grad.py:1250: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 7859 samples, validate on 3369 samples\n",
      "Epoch 1/10\n",
      "7859/7859 [==============================] - 4s 555us/step - loss: 1.4639 - acc: 0.6893 - val_loss: 0.9795 - val_acc: 0.7804\n",
      "Epoch 2/10\n",
      "7859/7859 [==============================] - 1s 163us/step - loss: 0.5887 - acc: 0.8707 - val_loss: 0.8429 - val_acc: 0.8097\n",
      "Epoch 3/10\n",
      "7859/7859 [==============================] - 1s 165us/step - loss: 0.3207 - acc: 0.9294 - val_loss: 0.8498 - val_acc: 0.8083\n",
      "Epoch 4/10\n",
      "7859/7859 [==============================] - 1s 163us/step - loss: 0.2274 - acc: 0.9483 - val_loss: 0.8989 - val_acc: 0.8032\n",
      "Epoch 5/10\n",
      "7859/7859 [==============================] - 1s 163us/step - loss: 0.1798 - acc: 0.9530 - val_loss: 0.9332 - val_acc: 0.7973\n",
      "Epoch 6/10\n",
      "7859/7859 [==============================] - 1s 164us/step - loss: 0.1640 - acc: 0.9552 - val_loss: 0.9187 - val_acc: 0.8085\n",
      "Epoch 7/10\n",
      "7859/7859 [==============================] - 1s 163us/step - loss: 0.1586 - acc: 0.9580 - val_loss: 0.9532 - val_acc: 0.8065\n",
      "Epoch 8/10\n",
      "7859/7859 [==============================] - 1s 162us/step - loss: 0.1551 - acc: 0.9578 - val_loss: 0.9662 - val_acc: 0.8065\n",
      "Epoch 9/10\n",
      "7859/7859 [==============================] - 1s 161us/step - loss: 0.1558 - acc: 0.9571 - val_loss: 0.9774 - val_acc: 0.8062\n",
      "Epoch 10/10\n",
      "7859/7859 [==============================] - 1s 164us/step - loss: 0.1514 - acc: 0.9592 - val_loss: 1.0193 - val_acc: 0.7993\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2352c624a08>"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DNN_model.fit(x_train, y_train, validation_data=(x_test, y_test), epochs=10, batch_size=64, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3369/3369 [==============================] - 0s 98us/step\n"
     ]
    }
   ],
   "source": [
    "scores = DNN_model.evaluate(x_test, y_test, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss =  1.019323904672126\n",
      "Accuracy =  0.7993469872454148\n"
     ]
    }
   ],
   "source": [
    "print('Test loss = ', scores[0])\n",
    "print('Accuracy = ', scores[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
